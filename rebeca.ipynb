{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imutils in /home/rebeca/.local/lib/python3.10/site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_content(image, threshold=0.4):\n",
    "    height, width, _ = image.shape\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray = cv2.GaussianBlur(image_gray, (7, 7), 0)\n",
    "    # cv2_imshow(image_gray)\n",
    "    # plt.hist(image_gray.ravel(), 256,[0, 256]); plt.show()\n",
    "    (T, image_threshold) = cv2.threshold(image_gray, 55, 255, cv2.THRESH_BINARY_INV)\n",
    "    # cv2_imshow(image_threshold)\n",
    "    contours = cv2.findContours(image_threshold .copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    image_clone = image.copy()\n",
    "    cv2.drawContours(image_clone, contours, -1, (255, 0, 0), 2)\n",
    "    # cv2_imshow(image_clone)\n",
    "    areas = [cv2.contourArea(contour) for contour in contours]\n",
    "    (contours, areas) = zip(*sorted(zip(contours, areas), key=lambda a:a[1]))\n",
    "    image_clone = image.copy()\n",
    "    cv2.drawContours(image_clone, [contours[-1]], -1, (255, 0, 0), 2)\n",
    "    # cv2_imshow(image_clone)\n",
    "    image_clone = image.copy()\n",
    "    (x, y, w, h) = cv2.boundingRect(contours[-1])\n",
    "    aspectRatio = h / float(height)\n",
    "    # print(aspectRatio)\n",
    "    if aspectRatio > threshold:\n",
    "        cv2.rectangle(image_clone, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(image_clone, \"High\", (x + 10, y + 20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
    "        # cv2_imshow(image_clone)\n",
    "        return True\n",
    "    else:\n",
    "        cv2.rectangle(image_clone, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        cv2.putText(image_clone, \"Low\", (x + 10, y + 20), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "        # cv2_imshow(image_clone)\n",
    "        return False\n",
    "    # cv2_imshow(image_clone)\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smashed_detector(image, threshold = 0.4):\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray = cv2.GaussianBlur(image_gray, (7, 7), 0)\n",
    "    border = cv2.Canny(image_gray, 30, 150)\n",
    "    contours = cv2.findContours(border.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    for contour in contours:\n",
    "        perimetro = cv2.arcLength(contour, True)\n",
    "        aproximacao = cv2.approxPolyDP(contour, 0.02 * perimetro, True)\n",
    "        if len(aproximacao) == 4:\n",
    "           cv2.drawContours(image, [contour], -1, (0, 255, 0), 2)\n",
    "           cv2.putText(image, 'Garrafa Quebrada', (10, 30), cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n",
    "        else:\n",
    "           cv2.drawContours(image, [contour], -1, (0, 0, 255), 2)\n",
    "           cv2.putText(image, 'Garrafa Inteira', (10, 30), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n",
    "    #cv2.imshow('smashed bottle', image)\n",
    "    #cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def white_detector_rgb(image, threshold=0.27):\n",
    "    lower_white = np.array([200, 200, 200], dtype=np.uint8)\n",
    "    upper_white = np.array([255, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    mask_white = cv2.inRange(image, lower_white, upper_white)\n",
    "\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    white_pixels = np.sum(mask_white) // 255\n",
    "    white_relation = white_pixels / total_pixels\n",
    "\n",
    "    return white_relation>= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_of_place(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 100)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi/180, 51)\n",
    "    horizontal_lines = 0\n",
    "    vertical_lines = 0\n",
    "    ignored_lines = 0\n",
    "     \n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            _, theta = line[0]\n",
    "            theta_degrees = np.degrees(theta)\n",
    "\n",
    "            if 10 <= theta_degrees <= 170:\n",
    "                horizontal_lines += 1\n",
    "            elif 80 <= theta_degrees <= 100:\n",
    "                ignored_lines += 1\n",
    "            else:\n",
    "                vertical_lines += 1\n",
    "\n",
    "        if horizontal_lines >= vertical_lines or ignored_lines == len(lines) or len(lines) == 0:\n",
    "           on_place = True\n",
    "        else:\n",
    "            on_place = False\n",
    "    else:\n",
    "        on_place = True  \n",
    "\n",
    "    return on_place\n",
    "\n",
    "   \n",
    "          \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_detector(image, threshold = 0.135):\n",
    "    bottle_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    bottle_gray = cv2.GaussianBlur(bottle_gray, (7, 7), 0)\n",
    "    (T, bottle_threshold) = cv2.threshold(bottle_gray, 55, 255, cv2.THRESH_BINARY_INV)\n",
    "    black_segment = cv2.bitwise_and(image, image, mask=bottle_threshold)\n",
    "    # cv2_imshow(black_segment)\n",
    "\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    black_pixels = np.sum(bottle_threshold) // 255\n",
    "    black_percentage = black_pixels / total_pixels\n",
    "    # print(f'Percentual de preto: {black_percentage}')\n",
    "\n",
    "    return black_percentage >= threshold\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def red_detector_rgb(image, threshold=0.4):\n",
    "    lower_red = np.array([0, 0, 100])\n",
    "    upper_red = np.array([100, 100, 255]) \n",
    "    mask_red_rgb = cv2.inRange(image, lower_red, upper_red)\n",
    "    contours, _ = cv2.findContours(mask_red_rgb, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "    total_area = 0\n",
    "    for contour in contours:\n",
    "        total_area += cv2.contourArea(contour)\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    red_img = total_area / total_pixels\n",
    "\n",
    "    return red_img >= threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottom_treatment(img):\n",
    "    height, width, _ = img.shape\n",
    "    response = np.zeros(8)\n",
    "\n",
    "    # Dividindo a imagem em 3 partes\n",
    "    third_length = width // 3\n",
    "\n",
    "    \n",
    "    bottle2 = img[:, third_length:2*third_length]\n",
    "    \n",
    "\n",
    "    middle_cap = bottle2[:height//5, :]\n",
    "    middle_cover = bottle2[170:305, :]\n",
    "    middle_neck = bottle2[40:185, :]\n",
    "\n",
    "    #verificando as caracteristicas\n",
    "    full = black_detector(middle_neck)\n",
    "    capped = red_detector_rgb(middle_cap, threshold=0.3)\n",
    "    redCover = red_detector_rgb(middle_cover)\n",
    "    whiteCover = white_detector_rgb(middle_cover)\n",
    "    covered = redCover or whiteCover\n",
    "    unlabeled = black_detector(middle_cover, threshold=0.42)\n",
    "\n",
    "    if full or capped or covered:\n",
    "        if not capped:\n",
    "            response[2] = 1\n",
    "        if whiteCover:\n",
    "            response[4] = 1\n",
    "        if unlabeled:\n",
    "            response[6] = 1\n",
    "        if not unlabeled and not out_of_place(middle_cover):\n",
    "            response[5] = 1\n",
    "        if full:\n",
    "            if verify_content(middle_neck):\n",
    "                response[0] = 1\n",
    "        else:\n",
    "            response[1] = 1\n",
    "    else:\n",
    "        response[7] = 1\n",
    "\n",
    "    return response\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_1.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_2.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_3.jpg\n",
      "[1. 0. 1. 0. 0. 1. 0. 0.]\n",
      "train_4.jpg\n",
      "[1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "train_5.jpg\n",
      "[1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "train_6.jpg\n",
      "[1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "train_7.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_8.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_9.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "train_10.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_11.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_12.jpg\n",
      "[1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "train_13.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "train_14.jpg\n",
      "[0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "train_15.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_16.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_17.jpg\n",
      "[0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "train_18.jpg\n",
      "[1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "train_19.jpg\n",
      "[1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "train_20.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_21.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_22.jpg\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "train_23.jpg\n",
      "[1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "train_24.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_25.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_26.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_27.jpg\n",
      "[1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "train_28.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_29.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_30.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_31.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_32.jpg\n",
      "[1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "train_33.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_34.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_35.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_36.jpg\n",
      "[0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "train_37.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "train_38.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_39.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_40.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_41.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_42.jpg\n",
      "[1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "train_43.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_44.jpg\n",
      "[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "train_45.jpg\n",
      "[0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "train_46.jpg\n",
      "[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "train_47.jpg\n",
      "[1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "train_48.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_49.jpg\n",
      "[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "train_50.jpg\n",
      "[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "train_51.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_52.jpg\n",
      "[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "train_53.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_54.jpg\n",
      "[0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "train_55.jpg\n",
      "[0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "train_56.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_57.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_58.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_59.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "train_60.jpg\n",
      "[0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "train_61.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_62.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_63.jpg\n",
      "[0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "train_64.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_65.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "train_66.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "train_67.jpg\n",
      "[1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "train_68.jpg\n",
      "[0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "train_69.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_70.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_71.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_72.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_73.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_74.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_75.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_76.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "train_77.jpg\n",
      "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#lendo as imagens7\n",
    "for i in range (1,78):\n",
    "  image = cv2.imread(f'train/train_{i}.jpg')\n",
    "  print(f'train_{i}.jpg')\n",
    "  #cv2.imshow(f\"train/train_{i}.jpg\", image) \n",
    "  #verify_content(image)\n",
    "  print(bottom_treatment(image))\n",
    "  #cv2.waitKey(0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
